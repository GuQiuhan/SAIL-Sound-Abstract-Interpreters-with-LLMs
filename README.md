# LLM-based DSL Generation for Neuron Specification

> A framework for step-by-step DSL generation using Large Language Models (LLMs).

This project aims to automate the generation of **neuron-level DSL constraints** using prompting techniques such as Chain-of-Thought (CoT), verification-guided refinement, and multi-model comparison. The system supports flexible prompt design, modular model interfaces, and robust evaluation workflows.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ generation                # Core LLM generation logic
â”‚   â”œâ”€â”€ prompt
â”‚   â”‚   â”œâ”€â”€ prompts           # (Few-shot) prompt examples and templates
â”‚   â”‚   â””â”€â”€ doc_collector.py  # Collects operator documentation to support grounding
â”‚   â”œâ”€â”€ controller.py         # Controls generation steps and retry logic
â”‚   â”œâ”€â”€ models.py             # Unified model interface for Llama, Gemini, etc.
â”‚   â”œâ”€â”€ request.py            # Prompt formatting and model communication
â”‚   â””â”€â”€ step_by_step.py       # Step-by-step constraint generation workflow
â”œâ”€â”€ results/                  # Outputs of models' generation
â”‚   â”œâ”€â”€ gemma-7b/
â”‚   â”‚   â”œâ”€â”€ success/
â”‚   â”‚   â””â”€â”€ failure/
â”‚   â”œâ”€â”€ llama3-1B/
â”‚   â”‚   â”œâ”€â”€ success/
â”‚   â”‚   â””â”€â”€ failure/
â”‚   â””â”€â”€ ...
â””â”€â”€ requirements.txt     # Python dependencies

```

## ğŸš€ Usage

### Configuration

#### Model Deployment
* Login in huggingface with your token, make sure have access to Llama3, Llama4, etc..
* Change the IP address of `MODEL_ENDPOINTS` in `generation/step_by_step.py` before deploying models.
### Documentation Collection
```bash
python generation/prompt/doc_collector.py
```
This tool scrapes and organizes PyTorch operator documentation for use in grounded prompting.

### Step-by-Step DSL Generation
```bash
python generation/step_by_step.py
```
This script guides the model to generate DSLs for neural operators using multi-stage reasoning and validation.



# TODO:

* read code of constraintflow and print out the counterexamples to prompt model
* package consranitflow
